{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO-7t1Y7-hV4"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kH16rnZ7wt_"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky3f_Odl-7um"
      },
      "source": [
        "## Data Transformations\n",
        "\n",
        "We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtssFUKb-jqx"
      },
      "outputs": [],
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                       transforms.RandomRotation((-30.0, 30.0), fill=([1, 1, 1,])),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(\n",
        "                                        (0.4914, 0.4822, 0.4465),\n",
        "                                        (0.2470, 0.2435, 0.2616)\n",
        "                                       )\n",
        "])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(\n",
        "                                        (0.4914, 0.4822, 0.4465),\n",
        "                                        (0.2470, 0.2435, 0.2616)\n",
        "                                       )\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQciFYo2B1mO"
      },
      "source": [
        "# Dataset and Creating Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4A84rlfDA23",
        "outputId": "040323fc-9946-47dd-da4c-b6ed94687cb1"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.CIFAR10('./data', train=True, download=True, transform=train_transforms)\n",
        "test_data = datasets.CIFAR10('./data', train=False, download=True, transform=test_transforms)\n",
        "\n",
        "batch_size=128\n",
        "kwargs = {\n",
        "    'batch_size': batch_size,\n",
        "    'shuffle': True,\n",
        "    'num_workers': 2,\n",
        "    'pin_memory': True}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, **kwargs)\n",
        "kwargs['shuffle']= False\n",
        "test_loader = torch.utils.data.DataLoader(test_data, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMcFk08JPcV3"
      },
      "outputs": [],
      "source": [
        "def get_layer(layer_type, in_channel=None, out_channel=None,\n",
        "              dropout_value=0.05):\n",
        "    if layer_type == 'C':\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channel,\n",
        "                      out_channels=out_channel,\n",
        "                      kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(out_channel, out_channel),\n",
        "            nn.Dropout(dropout_value)\n",
        "        )\n",
        "    elif layer_type == 'c':\n",
        "        return nn.Conv2d(in_channels=in_channel,\n",
        "                        out_channels=out_channel,\n",
        "                        kernel_size=(1, 1), padding=0, bias=False)\n",
        "    elif layer_type == 'P':\n",
        "        return nn.MaxPool2d(2, 2)\n",
        "    elif layer_type == 'G':\n",
        "        return nn.AdaptiveAvgPool2d(output_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khz8lxNDSfIt"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, schema, channels, dropout_value=0.01):\n",
        "        super(Net, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        for layer_type, channel_in, channel_out in zip(\n",
        "            schema, [3, *channels], channels):\n",
        "            self.layers.append(get_layer(\n",
        "                layer_type, channel_in, channel_out,\n",
        "                dropout_value))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3-vp8X9LCWo"
      },
      "source": [
        "# Model Params\n",
        "Can't emphasize on how important viewing Model Summary is.\n",
        "Unfortunately, there is no in-built model visualizer, so we have to take external help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5skB97zIJQQe",
        "outputId": "4c1702c7-4453-4eae-a0b9-cde534dbd438"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net(\n",
        "    list('CCcPCCCcPCCCGc'),\n",
        "    [64, 32, 16, 16,\n",
        "     8, 16, 16, 32, 32,\n",
        "     8, 16, 32, 32, 10]).to(device)\n",
        "summary(model, input_size=(3, 32, 32))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1__x_SbrL7z3"
      },
      "source": [
        "# Training and Testing\n",
        "\n",
        "Looking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs.\n",
        "\n",
        "Let's write train and test functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drokW8wWODKq"
      },
      "source": [
        "# Let's Train and test our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMCFxeAKOB53"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from model import train, test\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = StepLR(optimizer, step_size=4, gamma=0.05)\n",
        "\n",
        "EPOCHS =  20\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k29G-0w9N69M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "results_df = []\n",
        "for batch_idx, (data, target) in enumerate(test_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    pred_label = output.argmax(dim=1)\n",
        "    results_df.append(\n",
        "        pd.DataFrame({\"prediction\": pred_label,\n",
        "                      \"target\": target}))\n",
        "\n",
        "df = pd.concat(results_df).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "h_-y_tRk7sM3",
        "outputId": "0a8a0d5b-6ef5-45d5-a6ca-f36e16b6427c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "nrows = 2\n",
        "ncols = 5\n",
        "fig, axes = plt.subplots(nrows, ncols, figsize=(15, 10), )\n",
        "norm='layer'\n",
        "fig.suptitle(f\"Misclassification - norm:{norm}\", weight='bold', size=14)\n",
        "samples = df.query(\"prediction != target\").sample(10)\n",
        "axes = axes.ravel()\n",
        "\n",
        "plot_test_data = datasets.CIFAR10('./data', train=False, download=True,)\n",
        "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "for (ix, row), ax in zip(samples.iterrows(), axes):\n",
        "    img = plot_test_data[ix][0]\n",
        "    ax.imshow(img, interpolation='nearest')\n",
        "    ax.set_title(f'{class_labels[row.prediction]}| {class_labels[row.target]}', fontsize=12)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 ('minitorch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "36638de185fb471a9a02e922fc3d8d0083c97bdd69220bf5d8238d70706ae433"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
